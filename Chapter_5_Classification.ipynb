{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 5 - Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMp1KF44DFHbzArqw0AOrOq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hwanlee/my-practical-statistics-for-data-scientists/blob/main/Chapter_5_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt2F5iCBulij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd04c61a-20ae-4d24-81c3-2bef4e2f6a3e"
      },
      "source": [
        "# # Clone the repository\n",
        "# !git clone https://github.com/young-hwanlee/practical-statistics-for-data-scientists.git\n",
        "\n",
        "# # Open the file from the list of contents (File)\n",
        "# # Then, copy and paste it"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'practical-statistics-for-data-scientists'...\n",
            "remote: Enumerating objects: 363, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 363 (delta 75), reused 93 (delta 27), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (363/363), 83.68 MiB | 37.03 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practical Statistics for Data Scientists (Python)\n",
        "## Chapter 5. Classification\n",
        "> (c) 2019 Peter C. Bruce, Andrew Bruce, Peter Gedeck"
      ],
      "metadata": {
        "id": "yMaxJCFIqw3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required Python packages."
      ],
      "metadata": {
        "id": "0jmZ66YCrEyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression #, LogisticRegressionCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
        "from pygam import LinearGAM, s, f, l\n",
        "\n",
        "\n",
        "from dmba import classificationSummary\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "UndhZjX9rMWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "no display found. Using non-interactive Agg backend"
      ],
      "metadata": {
        "id": "igblvAtjrOxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     import common\n",
        "#     DATA = common.dataDirectory()\n",
        "# except ImportError:\n",
        "#     DATA = Path().resolve() / 'data'"
      ],
      "metadata": {
        "id": "qfqmIU2ErSIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths to data sets. If you don't keep your data in the same directory as the code, adapt the path names."
      ],
      "metadata": {
        "id": "_PyLZ9IMraEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LOAN3000_CSV = DATA / 'loan3000.csv'\n",
        "LOAN_DATA_CSV = DATA / 'loan_data.csv.gz'\n",
        "FULL_TRAIN_SET_CSV = DATA / 'full_train_set.csv.gz'"
      ],
      "metadata": {
        "id": "cq-m6WLRrcXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.1 Naive Bayes**\n",
        "## **5.1.2 The Naive Solution**\n"
      ],
      "metadata": {
        "id": "_v3XsYcirfWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan_data = pd.read_csv(LOAN_DATA_CSV)\n",
        "\n",
        "# convert to categorical\n",
        "loan_data.outcome = loan_data.outcome.astype('category')\n",
        "loan_data.outcome.cat.reorder_categories(['paid off', 'default'])\n",
        "loan_data.purpose_ = loan_data.purpose_.astype('category')\n",
        "loan_data.home_ = loan_data.home_.astype('category')\n",
        "loan_data.emp_len_ = loan_data.emp_len_.astype('category')\n",
        "\n",
        "predictors = ['purpose_', 'home_', 'emp_len_']\n",
        "outcome = 'outcome'\n",
        "X = pd.get_dummies(loan_data[predictors], prefix='', prefix_sep='')\n",
        "y = loan_data[outcome]\n",
        "\n",
        "naive_model = MultinomialNB(alpha=0.01, fit_prior=True)\n",
        "naive_model = MultinomialNB(alpha=0, fit_prior=False)\n",
        "naive_model.fit(X, y)\n",
        "\n",
        "new_loan = X.loc[146:146, :]\n",
        "print('predicted class: ', naive_model.predict(new_loan)[0])\n",
        "\n",
        "probabilities = pd.DataFrame(naive_model.predict_proba(new_loan),\n",
        "                             columns=naive_model.classes_)\n",
        "print('predicted probabilities',)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "g7-EgShVrsg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example not in book**"
      ],
      "metadata": {
        "id": "NhwnxE3vr5uS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Numerical variables are not supported in scikit-learn. The example would need to demonstrate binning a variable and display the probability distribution of the bins."
      ],
      "metadata": {
        "id": "Jx9IqhYfr_nh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "## example not in book\n",
        "less_naive <- NaiveBayes(outcome ~ borrower_score + payment_inc_ratio + \n",
        "                           purpose_ + home_ + emp_len_, data = loan_data)\n",
        "less_naive$table[1:2]\n",
        "\n",
        "png(filename=file.path(PSDS_PATH, 'figures', 'psds_naive_bayes.png'),  width = 4, height=3, units='in', res=300)\n",
        "\n",
        "stats <- less_naive$table[[1]]\n",
        "ggplot(data.frame(borrower_score=c(0,1)), aes(borrower_score)) +\n",
        "  stat_function(fun = dnorm, color='blue', linetype=1, \n",
        "                arg=list(mean=stats[1, 1], sd=stats[1, 2])) +\n",
        "  stat_function(fun = dnorm, color='red', linetype=2, \n",
        "                arg=list(mean=stats[2, 1], sd=stats[2, 2])) +\n",
        "  labs(y='probability')\n",
        "dev.off()\n",
        "```"
      ],
      "metadata": {
        "id": "543EAI8ksKj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.2 Discriminant Analysis**\n",
        "### **5.2.3 A Simple Example**"
      ],
      "metadata": {
        "id": "Umky9-zTsTlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan3000 = pd.read_csv(LOAN3000_CSV)\n",
        "loan3000.outcome = loan3000.outcome.astype('category')\n",
        "\n",
        "predictors = ['borrower_score', 'payment_inc_ratio']\n",
        "outcome = 'outcome'\n",
        "\n",
        "X = loan3000[predictors]\n",
        "y = loan3000[outcome]\n",
        "\n",
        "loan_lda = LinearDiscriminantAnalysis()\n",
        "loan_lda.fit(X, y)\n",
        "print(pd.DataFrame(loan_lda.scalings_, index=X.columns))"
      ],
      "metadata": {
        "id": "YJhWMDWssGkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(loan_lda.predict_proba(loan3000[predictors]),\n",
        "                    columns=loan_lda.classes_)\n",
        "print(pred.head())"
      ],
      "metadata": {
        "id": "fwbzpJxGssaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Figure 5.1**"
      ],
      "metadata": {
        "id": "uWwtCB95s3wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use scalings and center of means to determine decision boundary\n",
        "center = np.mean(loan_lda.means_, axis=0)\n",
        "slope = - loan_lda.scalings_[0] / loan_lda.scalings_[1]\n",
        "intercept = center[1] - center[0] * slope\n",
        "\n",
        "# payment_inc_ratio for borrower_score of 0 and 20\n",
        "x_0 = (0 - intercept) / slope\n",
        "x_20 = (20 - intercept) / slope\n",
        "\n",
        "lda_df = pd.concat([loan3000, pred['default']], axis=1)\n",
        "lda_df.head()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "g = sns.scatterplot(x='borrower_score', y='payment_inc_ratio',\n",
        "                    hue='default', data=lda_df, \n",
        "                    palette=sns.diverging_palette(240, 10, n=9, as_cmap=True),\n",
        "                    ax=ax, legend=False)\n",
        "\n",
        "ax.set_ylim(0, 20)\n",
        "ax.set_xlim(0.15, 0.8)\n",
        "ax.plot((x_0, x_20), (0, 20), linewidth=3)\n",
        "ax.plot(*loan_lda.means_.transpose())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qWaX4pcXtB5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.3 Logistic regression**\n",
        "### **5.3.1 Logistic Response Function and Logit**"
      ],
      "metadata": {
        "id": "P0FLTmINs_r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.arange(0.01, 1, 0.01)\n",
        "df = pd.DataFrame({\n",
        "    'p': p,\n",
        "    'logit': np.log(p / (1 - p)),\n",
        "    'odds': p / (1 - p),\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.axhline(0, color='grey', linestyle='--')\n",
        "ax.axvline(0.5, color='grey', linestyle='--')\n",
        "ax.plot(df['p'], df['logit'])\n",
        "ax.set_xlabel('Probability')\n",
        "ax.set_ylabel('logit(p)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IzOxfU5RtT4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3.2 Logistic Regression and the GLM**"
      ],
      "metadata": {
        "id": "qu-THnqFtXz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The package _scikit-learn_ has a specialised class for `LogisticRegression`. _Statsmodels_ has a more general method based on generalized linear model (GLM)."
      ],
      "metadata": {
        "id": "mpQCQZ8ZtdQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = ['payment_inc_ratio', 'purpose_', 'home_', 'emp_len_', \n",
        "              'borrower_score']\n",
        "outcome = 'outcome'\n",
        "X = pd.get_dummies(loan_data[predictors], prefix='', prefix_sep='', \n",
        "                   drop_first=True)\n",
        "y = loan_data[outcome] # .cat.categories\n",
        "\n",
        "logit_reg = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
        "logit_reg.fit(X, y)\n",
        "\n",
        "print('intercept ', logit_reg.intercept_[0])\n",
        "print('classes', logit_reg.classes_)\n",
        "pd.DataFrame({'coeff': logit_reg.coef_[0]}, \n",
        "             index=X.columns)"
      ],
      "metadata": {
        "id": "pJCcdBwptgYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the intercept and coefficients are reversed compared to the R model."
      ],
      "metadata": {
        "id": "uZo6uJGutlMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(loan_data['purpose_'].cat.categories)\n",
        "print(loan_data['home_'].cat.categories)\n",
        "print(loan_data['emp_len_'].cat.categories)"
      ],
      "metadata": {
        "id": "9OVgiSdWtnb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "_Not in book_ :\n",
        "If you have a feature or outcome variable that is ordinal, use the scikit-learn `OrdinalEncoder` to replace the categories (here, 'paid off' and 'default') with numbers. In the below code, we replace 'paid off' with 0 and 'default' with 1. This reverses the order of the predicted classes and as a consequence, the coefficients will be reversed."
      ],
      "metadata": {
        "id": "NkVO5QXStrrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc = OrdinalEncoder(categories=[['paid off', 'default']])\n",
        "y_enc = enc.fit_transform(loan_data[[outcome]]).ravel()\n",
        "\n",
        "logit_reg_enc = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
        "logit_reg_enc.fit(X, y_enc)\n",
        "\n",
        "print('intercept ', logit_reg_enc.intercept_[0])\n",
        "print('classes', logit_reg_enc.classes_)\n",
        "pd.DataFrame({'coeff': logit_reg_enc.coef_[0]}, \n",
        "             index=X.columns)"
      ],
      "metadata": {
        "id": "xx1z0sARtxeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3.4 Predicted Values from Logistic Regression**"
      ],
      "metadata": {
        "id": "oODW-hFtuD-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(logit_reg.predict_log_proba(X),\n",
        "                    columns=logit_reg.classes_)\n",
        "print(pred.describe())"
      ],
      "metadata": {
        "id": "Gjvsb4-uuKEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(logit_reg.predict_proba(X),\n",
        "                    columns=logit_reg.classes_)\n",
        "print(pred.describe())"
      ],
      "metadata": {
        "id": "ZFp5iKaRuNMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3.5 Interpreting the Coefficients and Odds Ratios**"
      ],
      "metadata": {
        "id": "5Nyio6OnuUps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(3, 3))\n",
        "ax.plot(df['logit'], df['odds'])\n",
        "ax.set_xlabel('log(odds ratio)')\n",
        "ax.set_ylabel('odds ratio')\n",
        "ax.set_xlim(0, 5.1)\n",
        "ax.set_ylim(-5, 105)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AAPT_UbSua3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.3.7 Assessing the Model**"
      ],
      "metadata": {
        "id": "Q7YeLBZsuhI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For comparison, here the GLM model using _statsmodels_. This method requires that the outcome is mapped to numbers."
      ],
      "metadata": {
        "id": "iqowT-EHulb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use GLM (general linear model) with the binomial family to \n",
        "# fit a logistic regression\n",
        "y_numbers = [1 if yi == 'default' else 0 for yi in y]\n",
        "logit_reg_sm = sm.GLM(y_numbers, X.assign(const=1), \n",
        "                      family=sm.families.Binomial())\n",
        "logit_result = logit_reg_sm.fit()\n",
        "print(logit_result.summary())"
      ],
      "metadata": {
        "id": "qo7p8p5Wupp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use splines."
      ],
      "metadata": {
        "id": "qu3ZnujMutm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "formula = ('outcome ~ bs(payment_inc_ratio, df=8) + purpose_ + ' +\n",
        "           'home_ + emp_len_ + bs(borrower_score, df=3)')\n",
        "model = smf.glm(formula=formula, data=loan_data, family=sm.families.Binomial())\n",
        "results = model.fit()\n",
        "print(results.summary())"
      ],
      "metadata": {
        "id": "bkUYxEvruwdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.genmod.generalized_linear_model import GLMResults\n",
        "def partialResidualPlot(model, df, outcome, feature, fig, ax):\n",
        "    y_actual = [0 if s == 'default' else 1 for s in df[outcome]]\n",
        "    y_pred = model.predict(df)\n",
        "    org_params = model.params.copy()\n",
        "    zero_params = model.params.copy()\n",
        "    # set model parametes of other features to 0\n",
        "    for i, name in enumerate(zero_params.index):\n",
        "        if feature in name:\n",
        "            continue\n",
        "        zero_params[i] = 0.0\n",
        "    model.initialize(model.model, zero_params)\n",
        "    feature_prediction = model.predict(df)\n",
        "    ypartial = -np.log(1/feature_prediction - 1)\n",
        "    ypartial = ypartial - np.mean(ypartial)\n",
        "    model.initialize(model.model, org_params)\n",
        "    results = pd.DataFrame({\n",
        "        'feature': df[feature],\n",
        "        'residual': -2 * (y_actual - y_pred),\n",
        "        'ypartial': ypartial/ 2,\n",
        "    })\n",
        "    results = results.sort_values(by=['feature'])\n",
        "\n",
        "    ax.scatter(results.feature, results.residual, marker=\".\", s=72./fig.dpi)\n",
        "    ax.plot(results.feature, results.ypartial, color='black')\n",
        "    ax.set_xlabel(feature)\n",
        "    ax.set_ylabel(f'Residual + {feature} contribution')\n",
        "    return ax\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "partialResidualPlot(results, loan_data, 'outcome', 'payment_inc_ratio', fig, ax)\n",
        "ax.set_xlim(0, 25)\n",
        "ax.set_ylim(-2.5, 2.5)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c-lqUyz1u3R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.4 Evaluating Classification Models**\n",
        "### **5.4.1 Confusion Matrix**"
      ],
      "metadata": {
        "id": "5OnZjoldu9yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "pred = logit_reg.predict(X)\n",
        "pred_y = logit_reg.predict(X) == 'default'\n",
        "true_y = y == 'default'\n",
        "true_pos = true_y & pred_y\n",
        "true_neg = ~true_y & ~pred_y\n",
        "false_pos = ~true_y & pred_y\n",
        "false_neg = true_y & ~pred_y\n",
        "\n",
        "conf_mat = pd.DataFrame([[np.sum(true_pos), np.sum(false_neg)], [np.sum(false_pos), np.sum(true_neg)]],\n",
        "                       index=['Y = default', 'Y = paid off'],\n",
        "                       columns=['Yhat = default', 'Yhat = paid off'])\n",
        "print(conf_mat)"
      ],
      "metadata": {
        "id": "mzXjXOTvvG1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y, logit_reg.predict(X)))"
      ],
      "metadata": {
        "id": "2HfRRY0pvKMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The package _dmba_ contains the function `classificationSummary` that prints confusion matrix and accuracy for a classification model."
      ],
      "metadata": {
        "id": "fmGM-TBpvMhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificationSummary(y, logit_reg.predict(X), \n",
        "                      class_names=logit_reg.classes_)"
      ],
      "metadata": {
        "id": "2NDXZ7B2vQcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.4.3 Precision, Recall, and Specificity**"
      ],
      "metadata": {
        "id": "MTl6fpDpvVGu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The _scikit-learn_ function `precision_recall_fscore_support` returns\n",
        "precision, recall, fbeta_score and support."
      ],
      "metadata": {
        "id": "QWLvkK-HviIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(y, logit_reg.predict(X))\n",
        "print('Precision', conf_mat[0, 0] / sum(conf_mat[:, 0]))\n",
        "print('Recall', conf_mat[0, 0] / sum(conf_mat[0, :]))\n",
        "print('Specificity', conf_mat[1, 1] / sum(conf_mat[1, :]))"
      ],
      "metadata": {
        "id": "KoI6OY0lvnbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_fscore_support(y, logit_reg.predict(X), \n",
        "                                labels=['default', 'paid off'])"
      ],
      "metadata": {
        "id": "jjroNiBxvqa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.4.4 ROC Curve**"
      ],
      "metadata": {
        "id": "uXyiu5xcvvk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function `roc_curve` in _Scikit-learn_ calculates all the information that is required for plotting a ROC curve."
      ],
      "metadata": {
        "id": "UfYvZUOqvzmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:, 0], \n",
        "                                 pos_label='default')\n",
        "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
        "\n",
        "ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xlim(1, 0)\n",
        "ax.plot((1, 0), (0, 1))\n",
        "ax.set_xlabel('specificity')\n",
        "ax.set_ylabel('recall')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W6aWd4LWv3tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.4.5 AUC**"
      ],
      "metadata": {
        "id": "yqC-5bScv9Fi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy can easily be calculated using the _scikit-learn_ function `accuracy_score`."
      ],
      "metadata": {
        "id": "kADJZ7h6wAea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum(roc_df.recall[:-1] * np.diff(1 - roc_df.specificity)))\n",
        "print(roc_auc_score([1 if yi == 'default' else 0 for yi in y], logit_reg.predict_proba(X)[:, 0]))"
      ],
      "metadata": {
        "id": "PwUiCL1UwDq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y, logit_reg.predict_proba(X)[:,0], \n",
        "                                 pos_label='default')\n",
        "roc_df = pd.DataFrame({'recall': tpr, 'specificity': 1 - fpr})\n",
        "\n",
        "ax = roc_df.plot(x='specificity', y='recall', figsize=(4, 4), legend=False)\n",
        "ax.set_ylim(0, 1)\n",
        "ax.set_xlim(1, 0)\n",
        "# ax.plot((1, 0), (0, 1))\n",
        "ax.set_xlabel('specificity')\n",
        "ax.set_ylabel('recall')\n",
        "ax.fill_between(roc_df.specificity, 0, roc_df.recall, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aY4IZqgRwHuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.5 Strategies for Imbalanced Data**\n",
        "### **5.5.1 Undersampling**\n",
        "> The results differ from the R version, however are equivalent to results obtained using the R code. Model based results are of similar magnitude."
      ],
      "metadata": {
        "id": "NkfWkUE_wL-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_set = pd.read_csv(FULL_TRAIN_SET_CSV)\n",
        "print(full_train_set.shape)"
      ],
      "metadata": {
        "id": "KAW2nILKwZHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('percentage of loans in default: ', \n",
        "print(      100 * np.mean(full_train_set.outcome == 'default')))"
      ],
      "metadata": {
        "id": "VoA_LdcIwc--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictors = ['payment_inc_ratio', 'purpose_', 'home_', 'emp_len_', \n",
        "              'dti', 'revol_bal', 'revol_util']\n",
        "outcome = 'outcome'\n",
        "X = pd.get_dummies(full_train_set[predictors], prefix='', prefix_sep='', \n",
        "                   drop_first=True)\n",
        "y = full_train_set[outcome]\n",
        "\n",
        "full_model = LogisticRegression(penalty='l2', C=1e42, solver='liblinear')\n",
        "full_model.fit(X, y)\n",
        "print('percentage of loans predicted to default: ', \n",
        "print(      100 * np.mean(full_model.predict(X) == 'default')))"
      ],
      "metadata": {
        "id": "bB_I1nhOwlzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(np.mean(full_train_set.outcome == 'default') / \n",
        " np.mean(full_model.predict(X) == 'default'))"
      ],
      "metadata": {
        "id": "Qv9sfmigwofp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.5.2 Oversampling and Up/Down Weighting**"
      ],
      "metadata": {
        "id": "FI-0QyfowttE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "default_wt = 1 / np.mean(full_train_set.outcome == 'default')\n",
        "wt = [default_wt if outcome == 'default' else 1 for outcome in full_train_set.outcome]\n",
        "\n",
        "full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
        "full_model.fit(X, y, wt)\n",
        "print('percentage of loans predicted to default (weighting): ', \n",
        "print(      100 * np.mean(full_model.predict(X) == 'default')))"
      ],
      "metadata": {
        "id": "h3lLaFg5w0oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.5.3 Data Generation**"
      ],
      "metadata": {
        "id": "hx0D3J45w9jc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The package _imbalanced-learn_ provides an implementation of the _SMOTE_ and similar algorithms."
      ],
      "metadata": {
        "id": "Iq56YIevxC-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
        "print('percentage of loans in default (SMOTE resampled): ', \n",
        "      100 * np.mean(y_resampled == 'default'))\n",
        "\n",
        "full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
        "full_model.fit(X_resampled, y_resampled)\n",
        "print('percentage of loans predicted to default (SMOTE): ', \n",
        "      100 * np.mean(full_model.predict(X) == 'default'))\n",
        "\n",
        "\n",
        "X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
        "print('percentage of loans in default (ADASYN resampled): ', \n",
        "      100 * np.mean(y_resampled == 'default'))\n",
        "\n",
        "full_model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
        "full_model.fit(X_resampled, y_resampled)\n",
        "print('percentage of loans predicted to default (ADASYN): ', \n",
        "print(      100 * np.mean(full_model.predict(X) == 'default')))"
      ],
      "metadata": {
        "id": "OJZiiixVxJJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5.5.5 Exploring the Predictions**"
      ],
      "metadata": {
        "id": "lylM43ebxNgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan3000 = pd.read_csv(LOAN3000_CSV)\n",
        "\n",
        "predictors = ['borrower_score', 'payment_inc_ratio']\n",
        "outcome = 'outcome'\n",
        "\n",
        "X = loan3000[predictors]\n",
        "y = loan3000[outcome]\n",
        "\n",
        "loan_tree = DecisionTreeClassifier(random_state=1, criterion='entropy', \n",
        "                                   min_impurity_decrease=0.003)\n",
        "loan_tree.fit(X, y)\n",
        "\n",
        "loan_lda = LinearDiscriminantAnalysis()\n",
        "loan_lda.fit(X, y)\n",
        "\n",
        "logit_reg = LogisticRegression(penalty=\"l2\", solver='liblinear')\n",
        "logit_reg.fit(X, y)\n",
        "\n",
        "\n",
        "## model\n",
        "gam = LinearGAM(s(0) + s(1))\n",
        "print(gam.gridsearch(X.values, [1 if yi == 'default' else 0 for yi in y]))"
      ],
      "metadata": {
        "id": "rwYwzP7GxTyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'Decision Tree': loan_tree,\n",
        "    'Linear Discriminant Analysis': loan_lda,\n",
        "    'Logistic Regression': logit_reg,\n",
        "    'Generalized Additive Model': gam,\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(5, 5))\n",
        "\n",
        "xvalues = np.arange(0.25, 0.73, 0.005)\n",
        "yvalues = np.arange(-0.1, 20.1, 0.1)\n",
        "xx, yy = np.meshgrid(xvalues, yvalues)\n",
        "X = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "boundary = {}\n",
        "\n",
        "for n, (title, model) in enumerate(models.items()):\n",
        "    ax = axes[n // 2, n % 2]\n",
        "    predict = model.predict(X)\n",
        "    if 'Generalized' in title:\n",
        "        Z = np.array([1 if z > 0.5 else 0 for z in predict])\n",
        "    else:\n",
        "        \n",
        "        Z = np.array([1 if z == 'default' else 0 for z in predict])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    boundary[title] = yvalues[np.argmax(Z > 0, axis=0)]\n",
        "    boundary[title][Z[-1,:] == 0] = yvalues[-1]\n",
        "\n",
        "    c = ax.pcolormesh(xx, yy, Z, cmap='Blues', vmin=0.1, vmax=1.3, shading='auto')\n",
        "    ax.set_title(title)\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3eFoKRh7xYX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boundary['borrower_score'] = xvalues\n",
        "boundaries = pd.DataFrame(boundary)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "boundaries.plot(x='borrower_score', ax=ax)\n",
        "ax.set_ylabel('payment_inc_ratio')\n",
        "ax.set_ylim(0, 20)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pq213oQOpxH2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}