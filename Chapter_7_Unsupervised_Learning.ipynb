{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 7 - Unsupervised Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFphaEvPmiVAHRDfwmv6Iq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hwanlee/my-practical-statistics-for-data-scientists/blob/main/Chapter_7_Unsupervised_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSfIrOHbuzSt"
      },
      "source": [
        "# # Clone the repository\n",
        "# !git clone https://github.com/young-hwanlee/practical-statistics-for-data-scientists.git\n",
        "\n",
        "# # Open the file from the list of contents (File)\n",
        "# # Then, copy and paste it"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practical Statistics for Data Scientists (Python)\n",
        "## Chapter 7. Unsupervised Learning\n",
        "> (c) 2019 Peter C. Bruce, Andrew Bruce, Peter Gedeck"
      ],
      "metadata": {
        "id": "geXy_eB6wK_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required Python packages."
      ],
      "metadata": {
        "id": "idwifSoowQIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prince"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9zGrb8NgCf6",
        "outputId": "3d3735df-42fd-4a8e-e50f-77b63807cc8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prince\n",
            "  Downloading prince-0.7.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from prince) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from prince) (1.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from prince) (1.3.5)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from prince) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from prince) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->prince) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->prince) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->prince) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->prince) (1.1.0)\n",
            "Installing collected packages: prince\n",
            "Successfully installed prince-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "import prince\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm \n",
        "from matplotlib.colors import from_levels_and_colors\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "print()"
      ],
      "metadata": {
        "id": "v5uGjdjmwguV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fb0cc15-e23e-45ec-966c-07e2d4524d85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try:\n",
        "#     import common\n",
        "#     DATA = common.dataDirectory()\n",
        "# except ImportError:\n",
        "#     DATA = Path().resolve() / 'data'"
      ],
      "metadata": {
        "id": "NVK1A7v9w0u2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define paths to data sets. If you don't keep your data in the same directory as the code, adapt the path names."
      ],
      "metadata": {
        "id": "yE-Or8Qqw5hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SP500_DATA_CSV = DATA / 'sp500_data.csv.gz'\n",
        "# SP500_SECTORS_CSV = DATA / 'sp500_sectors.csv'\n",
        "# LOAN_DATA_CSV = DATA / 'loan_data.csv.gz'\n",
        "# HOUSE_TASKS_CSV = DATA / 'housetasks.csv'\n",
        "\n",
        "DATA = 'https://raw.githubusercontent.com/young-hwanlee/practical-statistics-for-data-scientists/master/data/'\n",
        "\n",
        "SP500_DATA_CSV = DATA + 'sp500_data.csv.gz'\n",
        "SP500_SECTORS_CSV = DATA + 'sp500_sectors.csv'\n",
        "LOAN_DATA_CSV = DATA + 'loan_data.csv.gz'\n",
        "HOUSE_TASKS_CSV = DATA + 'housetasks.csv'"
      ],
      "metadata": {
        "id": "iU94oaoVw8kg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.1 Principal Components Analysis**\n",
        "### **7.1.1 A simple example**"
      ],
      "metadata": {
        "id": "QavXEst0xbYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp500_px = pd.read_csv(SP500_DATA_CSV, index_col=0)\n",
        "oil_px = sp500_px[['XOM', 'CVX']]\n",
        "print(oil_px.head())"
      ],
      "metadata": {
        "id": "bP8aZTe7xinD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d17b711-7f91-49c7-d35f-5c6dce46787d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 XOM       CVX\n",
            "1993-01-29 -0.016991  0.072921\n",
            "1993-02-01  0.016991  0.102089\n",
            "1993-02-02  0.084954  0.029168\n",
            "1993-02-03  0.067964  0.058337\n",
            "1993-02-04  0.034378  0.044272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcs = PCA(n_components=2)\n",
        "pcs.fit(oil_px)\n",
        "loadings = pd.DataFrame(pcs.components_, columns=oil_px.columns)\n",
        "print(loadings)"
      ],
      "metadata": {
        "id": "7w0icqb5xlHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9705d1f1-b020-4e48-b185-c5958a5fd463"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        XOM       CVX\n",
            "0 -0.664711 -0.747101\n",
            "1  0.747101 -0.664711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def abline(slope, intercept, ax):\n",
        "    \"\"\"Calculate coordinates of a line based on slope and intercept\"\"\"\n",
        "    x_vals = np.array(ax.get_xlim())\n",
        "    return (x_vals, intercept + slope * x_vals)\n",
        "\n",
        "ax = oil_px.plot.scatter(x='XOM', y='CVX', alpha=0.3, figsize=(4, 4))\n",
        "ax.set_xlim(-3, 3)\n",
        "ax.set_ylim(-3, 3)\n",
        "ax.plot(*abline(loadings.loc[0, 'CVX'] / loadings.loc[0, 'XOM'], 0, ax),\n",
        "        '--', color='C1')\n",
        "ax.plot(*abline(loadings.loc[1, 'CVX'] / loadings.loc[1, 'XOM'], 0, ax),\n",
        "        '--', color='C1')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KKoQHL7nxr1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.1.3 Interpreting principal components**"
      ],
      "metadata": {
        "id": "zmi5HIRjxxtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syms = sorted(['AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX', 'XOM', 'SLB', 'COP',\n",
        "        'JPM', 'WFC', 'USB', 'AXP', 'WMT', 'TGT', 'HD', 'COST'])\n",
        "top_sp = sp500_px.loc[sp500_px.index >= '2011-01-01', syms]\n",
        "\n",
        "sp_pca = PCA()\n",
        "sp_pca.fit(top_sp)\n",
        "\n",
        "explained_variance = pd.DataFrame(sp_pca.explained_variance_)\n",
        "ax = explained_variance.head(10).plot.bar(legend=False, figsize=(4, 4))\n",
        "ax.set_xlabel('Component')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M3s5QaDox1cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loadings = pd.DataFrame(sp_pca.components_[0:5, :], \n",
        "                        columns=top_sp.columns)\n",
        "print(loadings)"
      ],
      "metadata": {
        "id": "eTTA3hc0x57s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxPC = 1.01 * np.max(np.max(np.abs(loadings.loc[0:5, :])))\n",
        "\n",
        "f, axes = plt.subplots(5, 1, figsize=(5, 5), sharex=True)\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    pc_loadings = loadings.loc[i, :]\n",
        "    colors = ['C0' if l > 0 else 'C1' for l in pc_loadings]\n",
        "    ax.axhline(color='#888888')\n",
        "    pc_loadings.plot.bar(ax=ax, color=colors)\n",
        "    ax.set_ylabel(f'PC{i+1}')\n",
        "    ax.set_ylim(-maxPC, maxPC)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0gjQlBxix9Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.1.4 Correspondence analysis**"
      ],
      "metadata": {
        "id": "hQjD3cTGx9-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housetasks = pd.read_csv(HOUSE_TASKS_CSV, index_col=0)\n",
        "\n",
        "ca = prince.CA(n_components=2)\n",
        "ca = ca.fit(housetasks)\n",
        "\n",
        "ca.plot_coordinates(housetasks, figsize=(6, 6))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7OyIGSqFyPVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.2 K-Means Clustering**\n",
        "### **7.2.1 A Simple Example**"
      ],
      "metadata": {
        "id": "H1PuHvKJyUK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sp500_px.loc[sp500_px.index >= '2011-01-01', ['XOM', 'CVX']]\n",
        "kmeans = KMeans(n_clusters=4).fit(df)\n",
        "df['cluster'] = kmeans.labels_\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "epyzkVsMybpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centers = pd.DataFrame(kmeans.cluster_centers_, columns=['XOM', 'CVX'])\n",
        "print(centers)"
      ],
      "metadata": {
        "id": "LQBZxa02ycvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "ax = sns.scatterplot(x='XOM', y='CVX', hue='cluster', style='cluster', \n",
        "                     ax=ax, data=df)\n",
        "ax.set_xlim(-3, 3)\n",
        "ax.set_ylim(-3, 3)\n",
        "centers.plot.scatter(x='XOM', y='CVX', ax=ax, s=50, color='black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "65Lt2mPdygf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.2.2 K-Means Algorithm**\n",
        "The _scikit-learn_ algorithm is repeated 10 times by default (`n_init`), `max_iter` is used to control the number of iterations."
      ],
      "metadata": {
        "id": "4I9l9OM5ymat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syms = sorted(['AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX', 'XOM', 'SLB', 'COP', \n",
        "               'JPM', 'WFC', 'USB', 'AXP', 'WMT', 'TGT', 'HD', 'COST'])\n",
        "top_sp = sp500_px.loc[sp500_px.index >= '2011-01-01', syms]\n",
        "kmeans = KMeans(n_clusters=5).fit(top_sp)"
      ],
      "metadata": {
        "id": "ZQ6UkXF-y7ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.2.3 Interpreting the Clusters**"
      ],
      "metadata": {
        "id": "a5P8BqiFzAAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(Counter(kmeans.labels_))"
      ],
      "metadata": {
        "id": "0xhlDVEFy_d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "centers = pd.DataFrame(kmeans.cluster_centers_, columns=syms)\n",
        "\n",
        "f, axes = plt.subplots(5, 1, figsize=(5, 6), sharex=True)\n",
        "for i, ax in enumerate(axes):\n",
        "    center = centers.loc[i, :]\n",
        "    maxPC = 1.01 * np.max(np.max(np.abs(center)))\n",
        "    colors = ['C0' if l > 0 else 'C1' for l in center]\n",
        "    ax.axhline(color='#888888')\n",
        "    center.plot.bar(ax=ax, color=colors)\n",
        "    ax.set_ylabel(f'Cluster {i + 1}')\n",
        "    ax.set_ylim(-maxPC, maxPC)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s6NdFzJwzHVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.2.4 Selecting the Number of Clusters**"
      ],
      "metadata": {
        "id": "y1wSNQVIzOQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inertia = []\n",
        "for n_clusters in range(2, 15):\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(top_sp)\n",
        "    inertia.append(kmeans.inertia_ / n_clusters)\n",
        "inertias = pd.DataFrame({'n_clusters': range(2, 15), 'inertia': inertia})\n",
        "ax = inertias.plot(x='n_clusters', y='inertia')\n",
        "plt.xlabel('Number of clusters(k)')\n",
        "plt.ylabel('Average Within-Cluster Squared Distances')\n",
        "plt.ylim((0, 1.1 * inertias.inertia.max()))\n",
        "ax.legend().set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "64wfxIq1zTYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.3 Hierarchical Clustering**\n",
        "### **7.3.1 A Simple Example**"
      ],
      "metadata": {
        "id": "V_ViLwoPzVmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syms1 = ['AAPL', 'AMZN', 'AXP', 'COP', 'COST', 'CSCO', 'CVX', 'GOOGL', 'HD', \n",
        "         'INTC', 'JPM', 'MSFT', 'SLB', 'TGT', 'USB', 'WFC', 'WMT', 'XOM']\n",
        "df = sp500_px.loc[sp500_px.index >= '2011-01-01', syms1].transpose()\n",
        "\n",
        "Z = linkage(df, method='complete')\n",
        "print(Z.shape)"
      ],
      "metadata": {
        "id": "3o7oLzLizgPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.3.2 The Dendrogram**"
      ],
      "metadata": {
        "id": "hEBGV3vUzkhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "dendrogram(Z, labels=list(df.index), color_threshold=0)\n",
        "plt.xticks(rotation=90)\n",
        "ax.set_ylabel('distance')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nUx1NDcbzsTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memb = fcluster(Z, 4, criterion='maxclust')\n",
        "memb = pd.Series(memb, index=df.index)\n",
        "for key, item in memb.groupby(memb):\n",
        "    print(f\"{key} : {', '.join(item.index)}\")"
      ],
      "metadata": {
        "id": "PHOUiGT6zwwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.3.4 Measures of Dissimilarity**"
      ],
      "metadata": {
        "id": "B4U1o1I6zxji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sp500_px.loc[sp500_px.index >= '2011-01-01', ['XOM', 'CVX']]\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(5, 5))\n",
        "for i, method in enumerate(['single', 'average', 'complete', 'ward']):\n",
        "    ax = axes[i // 2, i % 2]\n",
        "    Z = linkage(df, method=method)\n",
        "    colors = [f'C{c+1}' for c in fcluster(Z, 4, criterion='maxclust')]\n",
        "    ax = sns.scatterplot(x='XOM', y='CVX', hue=colors, style=colors,\n",
        "                         size=0.5, ax=ax, data=df, legend=False)\n",
        "\n",
        "    ax.set_xlim(-3, 3)\n",
        "    ax.set_ylim(-3, 3)\n",
        "    ax.set_title(method)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7xRpjDhez6KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.4 Model based clustering**\n",
        "### **7.4.1 Multivariate Normal Distribution**\n",
        "Define a colormap that corresponds to the probability levels."
      ],
      "metadata": {
        "id": "VlCec4Q0z94g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = [0.5, -0.5]\n",
        "cov = [[1, 1], [1, 2]]\n",
        "probability = [.5, .75, .95, .99]\n",
        "def probLevel(p):\n",
        "    D = 1\n",
        "    return (1 - p) / (2 * math.pi * D)\n",
        "levels = [probLevel(p) for p in probability]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "x, y = np.mgrid[-2.8:3.8:.01, -5:4:.01]\n",
        "pos = np.empty(x.shape + (2,))\n",
        "pos[:, :, 0] = x; pos[:, :, 1] = y\n",
        "rv = multivariate_normal(mean, cov)\n",
        "\n",
        "\n",
        "CS = ax.contourf(x, y, rv.pdf(pos), cmap=cm.GnBu, levels=50)\n",
        "ax.contour(CS, levels=levels, colors=['black'])\n",
        "ax.plot(*mean, color='black', marker='o')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K8NQvaiR0S_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.4.2 Mixtures of Normals**"
      ],
      "metadata": {
        "id": "RlW5mkt60Y64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sp500_px.loc[sp500_px.index >= '2011-01-01', ['XOM', 'CVX']]\n",
        "mclust = GaussianMixture(n_components=2).fit(df)\n",
        "print(mclust.bic(df))"
      ],
      "metadata": {
        "id": "KNWB_s7_0dJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "colors = [f'C{c}' for c in mclust.predict(df)]\n",
        "df.plot.scatter(x='XOM', y='CVX', c=colors, alpha=0.5, ax=ax)\n",
        "ax.set_xlim(-3, 3)\n",
        "ax.set_ylim(-3, 3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I_rRVxjb0fu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Mean')\n",
        "print(mclust.means_)\n",
        "print('Covariances')\n",
        "print(mclust.covariances_)"
      ],
      "metadata": {
        "id": "066Nkj670h_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.4.3 Selecting the number of clusters**"
      ],
      "metadata": {
        "id": "5vfIlKjr0nUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "covariance_types = ['full', 'tied', 'diag', 'spherical']\n",
        "for n_components in range(1, 9):\n",
        "    for covariance_type in covariance_types:\n",
        "        mclust = GaussianMixture(n_components = n_components, warm_start=True,\n",
        "                                 covariance_type = covariance_type)\n",
        "        mclust.fit(df)\n",
        "        results.append({\n",
        "            'bic': mclust.bic(df),\n",
        "            'n_components': n_components,\n",
        "            'covariance_type': covariance_type,\n",
        "        })\n",
        "        \n",
        "results = pd.DataFrame(results)\n",
        "\n",
        "colors = ['C0', 'C1', 'C2', 'C3']\n",
        "styles = ['C0-','C1:','C0-.', 'C1--']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "for i, covariance_type in enumerate(covariance_types):\n",
        "    subset = results.loc[results.covariance_type == covariance_type, :]\n",
        "    subset.plot(x='n_components', y='bic', ax=ax, label=covariance_type, \n",
        "                kind='line', style=styles[i]) # , color=colors[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DHtrfJF20thS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.5 Scaling and Categorical Variables**\n",
        "### **7.5.1 Scaling the Variables**"
      ],
      "metadata": {
        "id": "UiAroLJy0wGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loan_data = pd.read_csv(LOAN_DATA_CSV)\n",
        "loan_data['outcome'] = pd.Categorical(loan_data['outcome'], \n",
        "                                      categories=['paid off', 'default'], \n",
        "                                      ordered=True)\n",
        "defaults = loan_data.loc[loan_data['outcome'] == 'default',]\n",
        "\n",
        "columns = ['loan_amnt', 'annual_inc', 'revol_bal', 'open_acc', \n",
        "           'dti', 'revol_util']\n",
        "\n",
        "df = defaults[columns]\n",
        "kmeans = KMeans(n_clusters=4, random_state=1).fit(df)\n",
        "counts = Counter(kmeans.labels_)\n",
        "\n",
        "centers = pd.DataFrame(kmeans.cluster_centers_, columns=columns)\n",
        "centers['size'] = [counts[i] for i in range(4)]\n",
        "print(centers)"
      ],
      "metadata": {
        "id": "_KZ8Zlq61CwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "df0 = scaler.fit_transform(df * 1.0)\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, random_state=1).fit(df0)\n",
        "counts = Counter(kmeans.labels_)\n",
        "\n",
        "centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), \n",
        "                       columns=columns)\n",
        "centers['size'] = [counts[i] for i in range(4)]\n",
        "print(centers)"
      ],
      "metadata": {
        "id": "JJ2AalTf1E_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.5.2 Dominant Variables**"
      ],
      "metadata": {
        "id": "FKXVj3A-1JUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "syms = ['GOOGL', 'AMZN', 'AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX', 'XOM', \n",
        "        'SLB', 'COP', 'JPM', 'WFC', 'USB', 'AXP', 'WMT', 'TGT', 'HD', 'COST']\n",
        "top_sp1 = sp500_px.loc[sp500_px.index >= '2005-01-01', syms]\n",
        "\n",
        "sp_pca1 = PCA()\n",
        "sp_pca1.fit(top_sp1)\n",
        "\n",
        "explained_variance = pd.DataFrame(sp_pca1.explained_variance_)\n",
        "ax = explained_variance.head(10).plot.bar(legend=False, figsize=(4, 4))\n",
        "ax.set_xlabel('Component')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-RzI4ra1RVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loadings = pd.DataFrame(sp_pca1.components_[0:2, :], \n",
        "                        columns=top_sp1.columns)\n",
        "print(loadings.transpose())"
      ],
      "metadata": {
        "id": "t77ylVqW1XV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.5.3 Categorical Data and Gower's Distance**\n",
        "Currently not available in any of the standard packages. However work is in progress to add it to scikit-learn. We will update this notebook once it becomes available.  \n",
        "https://github.com/scikit-learn/scikit-learn/pull/9555/"
      ],
      "metadata": {
        "id": "yqeXcLQN1Ymo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = defaults[['dti', 'payment_inc_ratio', 'home_', 'purpose_']].loc[0:4, :]\n",
        "print(x)"
      ],
      "metadata": {
        "id": "ci-9auUe1slj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "###############################################################\n",
        "## Figure 7-13: Categorical data and Gower's distance\n",
        "\n",
        "x <- loan_data[1:5, c('dti', 'payment_inc_ratio', 'home_', 'purpose_')]\n",
        "x\n",
        "\n",
        "daisy(x, metric='gower')\n",
        "\n",
        "set.seed(301)\n",
        "df <- loan_data[sample(nrow(loan_data), 250),\n",
        "                c('dti', 'payment_inc_ratio', 'home_', 'purpose_')]\n",
        "d = daisy(df, metric='gower')\n",
        "hcl <- hclust(d)\n",
        "dnd <- as.dendrogram(hcl)\n",
        "\n",
        "png(filename=file.path(PSDS_PATH, 'figures', 'psds_0713.png'), width = 4, height=4, units='in', res=300)\n",
        "par(mar=c(0,5,0,0)+.1)\n",
        "plot(dnd, leaflab='none', ylab='distance')\n",
        "dev.off()\n",
        "\n",
        "dnd_cut <- cut(dnd, h=.5)\n",
        "df[labels(dnd_cut$lower[[1]]),]\n",
        "\n",
        "\n",
        "## Problems in clustering with mixed data types\n",
        "df <- model.matrix(~ -1 + dti + payment_inc_ratio + home_ + pub_rec_zero, data=defaults)\n",
        "df0 <- scale(df)\n",
        "km0 <- kmeans(df0, centers=4, nstart=10)\n",
        "centers0 <- scale(km0$centers, center=FALSE, scale=1/attr(df0, 'scaled:scale'))\n",
        "round(scale(centers0, center=-attr(df0, 'scaled:center'), scale=FALSE), 2)\n",
        "```"
      ],
      "metadata": {
        "id": "k7Oi0tp11zRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7.5.4 Problems with Clustering Mixed Data**"
      ],
      "metadata": {
        "id": "Wnm2TDNM2W8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['dti', 'payment_inc_ratio', 'home_', 'pub_rec_zero']\n",
        "df = pd.get_dummies(defaults[columns])\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "df0 = scaler.fit_transform(df * 1.0)\n",
        "kmeans = KMeans(n_clusters=4, random_state=1).fit(df0)\n",
        "centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), \n",
        "                       columns=df.columns)\n",
        "print(centers)"
      ],
      "metadata": {
        "id": "WB1b3pEQuAWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}