{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 2 - Data and Sampling Distributions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO/9iiVC4G51vbXedxWUmhG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/young-hwanlee/my-practical-statistics-for-data-scientists/blob/main/Chapter_2_Data_and_Sampling_Distributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xwLkRnZt92d"
      },
      "source": [
        "# **Practical Statistics for Data Scientists (Python)**\n",
        "# **Chapter 2. Data and Sampling Distributions**\n",
        "> (c) 2019 Peter C. Bruce, Andrew Bruce, and Peter Gedeck"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHIpEesA99Fs"
      },
      "source": [
        "Import required Python packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud0o1hDW-BL-"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.utils import resample\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BypqGvpP91_z"
      },
      "source": [
        "# try:\n",
        "#     import common\n",
        "#     DATA = common.dataDirectory()\n",
        "# except ImportError:\n",
        "#     DATA = Path().resolve() / 'data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMZy1Aa_-6jV"
      },
      "source": [
        "Define paths to data sets. If you don't keep your data in the same directory as the code, adapt the path names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU1dRE-V-wHc"
      },
      "source": [
        "DATA = 'https://raw.githubusercontent.com/young-hwanlee/practical-statistics-for-data-scientists/master/data/'\n",
        "\n",
        "LOANS_INCOME_CSV = DATA / 'loans_income.csv'\n",
        "SP500_DATA_CSV = DATA / 'sp500_data.csv.gz'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxaNzWVL-wb2"
      },
      "source": [
        "Figure 2.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTmTJGym-wql"
      },
      "source": [
        "np.random.seed(seed=1)\n",
        "x = np.linspace(-3, 3, 300)\n",
        "xsample = stats.norm.rvs(size=1000)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(5, 1.5))\n",
        "\n",
        "ax = axes[0]\n",
        "ax.fill(x, stats.norm.pdf(x))\n",
        "ax.set_axis_off()\n",
        "ax.set_xlim(-3, 3)\n",
        "\n",
        "ax = axes[1]\n",
        "ax.hist(xsample, bins=30)\n",
        "ax.set_axis_off()\n",
        "ax.set_xlim(-3, 3)\n",
        "ax.set_position\n",
        "# plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvezIUfdAjzH"
      },
      "source": [
        "## **2.3 Sampling Distribution of a Statistic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYbb9iVFAxpq"
      },
      "source": [
        "loans_incom = pd.read_csv(LOANS_INCOME_CSV, squeeze=True)\n",
        "\n",
        "sample_data = pd.DataFrame({\n",
        "    'income': loans_income.sample(1000),\n",
        "    'type': 'Data',\n",
        "})\n",
        "\n",
        "sample_mean_05 = pd.DataFrame({\n",
        "    'income': [loans_income.sample(5).mean() for _ in range(1000)],\n",
        "    'type': 'Mean of 5',\n",
        "})\n",
        "\n",
        "sample_mean_20 = pd.DataFrame({\n",
        "    'income': [loans_income.sample(20).mean() for _ in range(1000)],\n",
        "    'type': 'Mean of 20',\n",
        "})\n",
        "\n",
        "results = pd.concat([sample_data, sample_mean_05, sample_mean_20])\n",
        "print(results.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKeSIizuB-Cs"
      },
      "source": [
        "g = sns.FaceGrid(results, col='type', col_wrap=1,\n",
        "                 height=2, aspect=2)\n",
        "g.map(plt.hist, 'income', range=[0, 200000], bins=40)\n",
        "g.set_axis_labels('income', 'Count')\n",
        "g.set_titles('{col_name}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJB61qdhCezL"
      },
      "source": [
        "## **2.4 The Bootstrap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJNKxDzYClrq"
      },
      "source": [
        "results = []\n",
        "for nrepeat in range(1000):\n",
        "    sample = resample(loans_income)\n",
        "    results.append(sample.median())\n",
        "results = pd.Series(results)\n",
        "print('Bootstrap Statistics:')\n",
        "print(f'original: {loans_income.median()}')\n",
        "print(f'bias: {results.mean() - loans_income.median()}')\n",
        "print(f'std.error: {results.std()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLOlW6-LDT5p"
      },
      "source": [
        "## **2.5 Confidence Intervals**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfczjcm-Dg_h"
      },
      "source": [
        "print(loans_income.mean())\n",
        "np.random.seed(seed=3)\n",
        "\n",
        "# create a sample of 20 loan income data\n",
        "sample20 = resample(loans_income, n_samples=20, replace=False)\n",
        "print(sample20.mean())\n",
        "results = []\n",
        "for nrepeat in range(500):\n",
        "    sample = resample(sample20)\n",
        "    results.append(sample.mean())\n",
        "results = pd.Series(results)\n",
        "\n",
        "confidence_interval = list(results.quantile([0.05, 0.95]))\n",
        "ax = results.plot.hist(bins=30, figsize=(4, 3))\n",
        "ax.plot(confidence_interval, [55, 55], color='black')\n",
        "for x in confidence_interval:\n",
        "    ax.plot([x, x], [0, 65], color='black')\n",
        "    ax.text(x, 70, f'{x:.0f}',\n",
        "            horizontalalignment='center', verticalalignment='center')\n",
        "ax.text(sum(confidence_interval) / 2, 60, '90% interval',\n",
        "        horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "meanIncome = results.mean()\n",
        "ax.plot([meanIncome, meanIncome], [0, 50], color='black', linestyle='--')\n",
        "ax.text(meanIncome, 10, f'Mean: {meanIncome:.0f}',\n",
        "        bbox=dict(facecolor='white', edgecolor='white', alpha=0.5),\n",
        "        horizontalalignment='center', verticalalignment='center')\n",
        "ax.set_ylim(0, 80)\n",
        "ax.set_ylabel('Counts')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0AskpnQGE42"
      },
      "source": [
        "np.random.seed(seed=3)\n",
        "# create a sample of 20 loan income data\n",
        "sample20 = resample(loans_income, n_samples=20, replace=False)\n",
        "\n",
        "results = []\n",
        "for nrepeat in range(500):\n",
        "    sample = resample(sample20)\n",
        "    results.append(sample.mean())\n",
        "results = pd.Series(results)\n",
        "\n",
        "confidence_interval = list(results.quantile([0.05, 0.95]))\n",
        "ax = results.plot.hist(bins=30, figsize=(4, 3), color='C1')\n",
        "ax.plot(confidence_interval, [55, 55], color='black', linestyle='--')\n",
        "for x in confidence_interval:\n",
        "    ax.plot([x, x], [0, 60], color='black')\n",
        "ax.text(82000, 50, \n",
        "        f'90% CI\\n[{confidence_interval[0]:.0f}, {confidence_interval[1]:.0f}]',\n",
        "       fontsize='small')\n",
        "\n",
        "confidence_interval = list(results.quantile([0.025, 0.975]))\n",
        "ax = results.plot.hist(bins=30, figsize=(4, 3))\n",
        "ax.plot(confidence_interval, [65, 65], color='black', linestyle='--')\n",
        "for x in confidence_interval:\n",
        "    ax.plot([x, x], [0, 70], color='black')\n",
        "ax.text(82000, 65, \n",
        "        f'95% CI\\n[{confidence_interval[0]:.0f}, {confidence_interval[1]:.0f}]',\n",
        "       fontsize='small')\n",
        "# ax.text(sum(confidence_interval) / 2, 264, '95 % interval',\n",
        "#         horizontalalignment='center', verticalalignment='center')\n",
        "\n",
        "meanIncome = results.mean()\n",
        "ax.plot([meanIncome, meanIncome], [0, 50], color='black', linestyle='--')\n",
        "ax.text(meanIncome, 5, f'Mean: {meanIncome:.0f}',\n",
        "        bbox=dict(facecolor='white', edgecolor='white', alpha=0.5),\n",
        "        horizontalalignment='center', verticalalignment='center')\n",
        "ax.set_ylim(0, 80)\n",
        "ax.set_xlim(37000, 102000)\n",
        "ax.set_xticks([40000, 50000, 60000, 70000, 80000])\n",
        "ax.set_ylabel('Counts')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__i5sWadGNGc"
      },
      "source": [
        "## **2.6 Normal Distribution**\n",
        "### **2.6.1 Standard Normal and QQ-Plots**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cOjUvueIA5n"
      },
      "source": [
        "The package *scipy* has the function (scipy.stats.probplot) to create QQ-plots. The argument dist specifies the distribution, which is set by default to the normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bFlwSYRGdXt"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "\n",
        "norm_sample = stats.norm.rvs(size=100)\n",
        "stats.probplot(norm_sample, plot=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEMqRKq0Gguk"
      },
      "source": [
        "## **2.7 Long-Tailed Distributions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9_GcqtqGlgt"
      },
      "source": [
        "sp500_px = pd.read_csv(SP500_DATA_CSV)\n",
        "\n",
        "nflx = sp500_px.NFLX\n",
        "nflx = np.diff(np.log(nflx[nflx > 0]))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(4, 4))\n",
        "stats.probplot(nflx, plot=ax)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO9dAEQOGql0"
      },
      "source": [
        "## **2.9 Binomial Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZMjikjsGuYF"
      },
      "source": [
        "print(stats.binom.pmf(2, n=5, p=0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DVVi4lLJCEj"
      },
      "source": [
        "print(stats.binom.cdf(2, n=5, p=0.1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy133pTBG_LR"
      },
      "source": [
        "## **2.12 Poisson and Related Distribution**\n",
        "### **2.12.1 Poisson Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBtV1rKmHW6I"
      },
      "source": [
        "sample = stats.poisson.rvs(2, size=100)\n",
        "\n",
        "pd.Series(sample).plot.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e16WWnH0HGI9"
      },
      "source": [
        "### **2.12.2 Exponential Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7QdGIycHgm8"
      },
      "source": [
        "sample = stats.expon.rvs(scale=5, size=100)\n",
        "\n",
        "pd.Series(sample).plt.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1vZMVp7HzXv"
      },
      "source": [
        "### **2.12.4 Weibull Distribution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq4YgD-UH3bj"
      },
      "source": [
        "sample = stats.weibull_min.rvs(1.5, scale=5000, size=100)\n",
        "\n",
        "pd.Series(sample).plot.hist()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}